# -*- coding: utf-8 -*-
"""TF2.0 Autoregressive Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GQ6znYfssWqf7fSL8N1lAwBEpieUL-FZ

From: https://365datascience.com/tutorials/time-series-analysis-tutorials/autoregressive-model/
In time-series, we often observe similarities between past and present 
values. That’s because we encounter autocorrelation within such data. In 
other words, by knowing the price of a product today, we can often make a 
rough prediction about its valuation tomorrow. So, in this tutorial, we’re 
going to discuss a model that reflects this correlation.
– the autoregressive model.

What is an Autoregressive Model?
The Autoregressive Model, or AR model for short, relies only on past period 
values to predict current ones. It’s a linear model, where current period 
values are a sum of past outcomes multiplied by a numeric factor. We denote 
it as AR(p), where “p” is called the order of the model and represents the 
number of lagged values we want to include.

Here, we create a SIN wave to simulate a time-series...then analyze & predict
This would be the simplest possible RNN...(actually, not an RNN)

From: https://dzone.com/articles/recurrent-neural-networks-rnn-deep-learning-for-se
RNN vs Autoregressive Models
An autoregressive model is when a value from data with a temporal dimension 
are regressed on previous values up to a certain point specified by the user. 
An RNN works the same way but the obvious difference in comparison is that the 
RNN looks at all the data (i.e. it does not require a specific time period to 
                           be specified by the user.)
"""

# Commented out IPython magic to ensure Python compatibility.
# Install TensorFlow
# !pip install -q tensorflow-gpu==2.0.0-beta1

# try:
# #   %tensorflow_version 2.x  # Colab only.
# except Exception:
#   pass

#%% Imports
import time
import sys
import os
import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, GlobalMaxPooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import SGD, Adam

# following line works every where but Pyth 3.78/tensor 2.0

#%% Get GPU & TF status
print(tf.__version__)
from tensorflow.python.client import device_lib 
# print(device_lib.list_local_devices())  # this puts out a lot of lines (Gibberish?)
print('Conda Envronment:  ', os.environ['CONDA_DEFAULT_ENV'])
print(f'Gpu  Support:       {tf.test.is_built_with_gpu_support()}')
print(f'Cuda Support:       {tf.test.is_built_with_cuda()}')
print(f'Tensor Flow:        {tf.version.VERSION}')
pver = str(format(sys.version_info.major) +'.'+ format(sys.version_info.minor)+'.'+ format(sys.version_info.micro))
print('Python version:      {}.'.format(pver)) 
print('The numpy version:   {}.'.format(np.__version__))
# print('The panda version:   {}.'.format(pd.__version__))

condaenv = os.environ['CONDA_DEFAULT_ENV']

starttime = time.perf_counter()
modelstart = time.strftime('%c')


#%% Fabricate synthetic SIN wave data
series = np.sin(0.1*np.arange(200)) + np.random.randn(200)*0.1

#%% plot it
plt.plot(series)
plt.show()

#%% build the dataset
# let's see if we can use T past values to predict the next value
T = 10  # This is why this is autoregressive...we limit the back_values to 10
X = []
Y = []
for t in range(len(series) - T):
  x = series[t:t+T]
  X.append(x)
  y = series[t+T]
  Y.append(y)

X = np.array(X).reshape(-1, T)
Y = np.array(Y)
N = len(X)
print("X.shape", X.shape, "Y.shape", Y.shape)

#%% try autoregressive linear model
# This looks like an ANN! ??
i = Input(shape=(T,))
x = Dense(1)(i)
model = Model(i, x)  #  groups layers into an object with training and inference features.
model.compile(
  loss='mse',
  optimizer=Adam(lr=0.1),
)

#%% train the RNN
r = model.fit(
  X[:-N//2], Y[:-N//2],
  epochs=80,
  validation_data=(X[-N//2:], Y[-N//2:]),
)

#%% Plot loss per iteration
import matplotlib.pyplot as plt
plt.plot(r.history['loss'], label='loss')
plt.plot(r.history['val_loss'], label='val_loss')
plt.legend()

#%% "Wrong" forecast using true targets

validation_target = Y[-N//2:]
validation_predictions = []

# index of first validation input
i = -N//2

while len(validation_predictions) < len(validation_target):
  p = model.predict(X[i].reshape(1, -1))[0,0] # 1x1 array -> scalar
  i += 1
  
  # update the predictions list
  validation_predictions.append(p)

plt.plot(validation_target, label='forecast target')
plt.plot(validation_predictions, label='forecast prediction')
plt.legend()

# up above is all wrong.  Here's the right way...
#%% Forecast future values (use only self-predictions for making future predictions)

validation_target = Y[-N//2:]
validation_predictions = []

# first validation input
last_x = X[-N//2] # 1-D array of length T

while len(validation_predictions) < len(validation_target):
  p = model.predict(last_x.reshape(1, -1))[0,0] # 1x1 array -> scalar
  
  # update the predictions list
  validation_predictions.append(p)
  
  # make the new input
  # roll each column to the left, the leftmost 'rolls' around to the right...then it gets over written 
  last_x = np.roll(last_x, -1)
  last_x[-1] = p

endtime = time.perf_counter()
duration = round(endtime - starttime,2)

plt.style.use('classic')
plt.plot(r.history['loss'], label='loss')
plt.plot(r.history['val_loss'], label='val_loss')
plt.title(f'Udemy TF2 Lecture 43 {modelstart}\n ' +
          f'Auto Regressive Model: SINE wave (with Noise)')
plt.xlabel(f'Teaching Point: AutoRegressive can easily outperform an LSTM. Duration: {duration}')

plt.plot(validation_target, label='forecast target')
plt.plot(validation_predictions, label='forecast prediction')
plt.legend(fontsize=9)
