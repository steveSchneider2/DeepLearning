# -*- coding: utf-8 -*-
"""TF2.0 Fashion MNIST.ipynb
13 June: Adding Tensorboard callbacks.
Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XeVQQdyGNptGWBLclF3yVijNir5-upkF
    
12 Jan: Fully functional in Environment: P37TF22cu7  (actually TF21)

Convolution 
    --> Image modification...either addition or multiplication (or both)
    --> ie feature transformation... 
        like taking just the lines from an image (edge detection filter)
        like bluring a picture (gaussian filter)

alternative description of convolution:
    "A sliding pattern finder (looking for particular pattern)"
    

UDEMY TENSORFLOW 2.0 LECTURE 35  MNIST IMAGE CLASSIFICATION FASHION 60,000 RECORDS
RUNNING ON GPU: TAKES 107.8 SECONDS    
"""

''' Notes from the lecture #35:
It's Conv23 because there are two spatial dimensions; color is not a spatial dimension'
A time-varing signal (sound) would use Conv1D... only dimension is sound
A video (height, Width, Time) would use Conv3d
Medical imaging data (like cancer images) would have height, width, depth (use Conv3D)
Conv3D would use Voxel(s) (volumn element vs picture element)

# output feature maps (32) 
Filter dimensions (3, 3) ... the spatial dimensions
Stride controls the speed of the filter
Activiation 
Padding arguement; default is 'valid'... which comes w/o an entry.

Convolution is pattern finding...so you might not usually do dropouts in convolution...
    because you don't want to remove pixels before looking for the pattern (stroke)
    if you remove pixels, is the 'stroke' still visible
Tensor24 env:
2021-06-13 14:14:46.038368: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cupti64_110.dll'; dlerror: cupti64_110.dll not found
2021-06-13 14:14:46.039384: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cupti.dll'; dlerror: cupti.dll not found
2021-06-13 14:14:46.040247: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.
2021-06-13 14:14:46.040300: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-06-13 14:14:46.040326: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1496] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.
'''

# Commented out IPython magic to ensure Python compatibility.
# Install TensorFlow
# !pip install -q tensorflow-gpu==2.0.0-beta1

# try:
# #   %tensorflow_version 2.x  # Colab only.
# except Exception:
#   pass

#%% Imports...
import time
import sys
import tensorflow as tf
from datetime import datetime
import tensorboard
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
import os
import pandas as pd
from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout
from tensorflow.keras.models import Model
import pydot
import graphviz  #for graph of 
import GPUtil
gpus = GPUtil.getGPUs()

#%% Get GPU status
from tensorflow.python.client import device_lib 
# print(device_lib.list_local_devices())  # this puts out a lot of lines (Gibberish?)
print('Conda Envronment:  ', os.environ['CONDA_DEFAULT_ENV'])
print(f'Gpu  Support:       {tf.test.is_built_with_gpu_support()}')
print(f'Cuda Support:       {tf.test.is_built_with_cuda()}')
print(f'Tensor Flow:        {tf.version.VERSION}')
pver = str(format(sys.version_info.major) +'.'+ format(sys.version_info.minor)+'.'+ format(sys.version_info.micro))
print('Python version:      {}.'.format(pver)) 
print('The numpy version:   {}.'.format(np.__version__))
print('The panda version:   {}.'.format(pd.__version__))
print('Tensorboard version  {}.'.format(tensorboard.__version__))
# additional imports

condaenv = os.environ['CONDA_DEFAULT_ENV']

starttime = time.perf_counter()
modelstart = time.strftime('%c')
#%%  # Define the Keras TensorBoard callback.
logdir="d:/data/logs/logs/fit/" + datetime.now().strftime("%Y%m%d_%H%M%S")
tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)


#%% Load in the data
# Notice below, the dataset come INSIDE the tensorflow module...
# the 'load_data()' function returns two tuples.
# x_train is a numpy array (60000,  28, 28, 1); y_train(60000,)
fashion_mnist = tf.keras.datasets.fashion_mnist
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

#%% Normalization / Data Prep
x_train, x_test = x_train / 255.0, x_test / 255.0
print("x_train.shape:", x_train.shape)  # (60000, 28, 28)
type(x_train)
# the data is only 2D!
# convolution expects height x width x color
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)
print(x_train.shape)

# number of classes...cast y_train to a 'set', which only has unique values
K = len(set(y_train))
print("number of classes:", K)  # ie 10 classes; we knew this already but good to show the general case
set(y_train)  # ie:  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}

# ####################################################
#%% BUILD THE MODEL using the functional API
i = Input(shape=x_train[0].shape)
# convolution layers (3 of them): increasing the #of feature maps at each convolution layer
# This (doubling feature maps) is a 'pattern'... (he says)
#  Strides of 2 reduces the image dimension by half after each convolution --> he says this as if it is purposeful, by design
# Convolution layers do feature extraction; 
x = Conv2D(32, (3, 3), strides=2, activation='relu')(i)
x = Conv2D(64, (3, 3), strides=2, activation='relu')(x)
x = Conv2D(128, (3, 3), strides=2, activation='relu')(x)
# Convolution done...now just a 'simple' ANN... 'classification'
# And, that means...flatten() first
x = Flatten()(x)
x = Dropout(0.2)(x)  # for regularization
x = Dense(512, activation='relu')(x)
x = Dropout(0.2)(x)
x = Dense(K, activation='softmax')(x)

model = Model(i, x)

# ####################################################
#%% Compile and fit
# Note: make sure you are using the GPU for this!
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

#%% Train the model
epochs = 15
r = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs)

endtime = time.perf_counter()
duration = round(endtime - starttime,2)

#%% Graph the model
# import pydot
# import graphviz
from tensorflow import keras
# from tensorflow.keras import layers
keras.utils.plot_model(model, show_shapes=True)

#%% Show the model in text
import io
s = io.StringIO()
model.summary(print_fn=lambda x: s.write(x + '\n'))
model_summary = s.getvalue()
model_summary = model_summary.replace('=','')
model_summary = model_summary.replace('_','')
model_summary = model_summary.replace('\n\n','\n')

pver = str(format(sys.version_info.major) + '.' +
           format(sys.version_info.minor) + '.' +
           format(sys.version_info.micro))
model.summary()
#%% Plot loss per iteration multi-color chart!
import matplotlib.pyplot as plt

s2= """i = Input(shape=x_train[0].shape)
x = Conv2D(32, (3, 3), strides=2, activation='relu')(i)
x = Conv2D(64, (3, 3), strides=2, activation='relu')(x)
x = Conv2D(128, (3, 3), strides=2, activation='relu')(x)
x = Flatten()(x)
x = Dropout(0.2)(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.2)(x)
x = Dense(K, activation='softmax')(x)"""



plt.style.use('classic')
plt.plot(r.history['loss'], label='loss')
plt.plot(r.history['val_loss'], label='val_loss')
plt.legend()

# Plot accuracy per iteration
plt.plot(r.history['accuracy'], label='acc')
plt.plot(r.history['val_accuracy'], label='val_acc')
plt.legend()
plt.title(f'Udemy TensorFlow 2.0 Lecture 35 {modelstart}\n ' +
          f'Image Classification: Fashion MNIST {x_train.shape[0]} records ' +
          f'{x_train.shape[1]} size')
plt.xlabel(f'tf2_35_CNN_fashion_mnist.py  Convolutional NN  Duration: {duration}')
plt.ylim(0,1)
plt.text(.5, .7,# transform=trans1,
         s=s2,
         wrap=True, ha='left', va='bottom',
         fontsize=10, bbox=dict(facecolor='yellow', alpha=0.5))
plt.text(.5, .2,# transform=trans1,
         s=model_summary,
         wrap=True, ha='left', va='bottom', fontname='Consolas',
         fontsize=8, bbox=dict(facecolor='pink', alpha=0.5))
plt.text(.5, .02,# transform=trans1,
         s=f'Conda Envr:  {condaenv}\n' +
         f'Gpu  Support:       {tf.test.is_built_with_gpu_support()}\n' +
         f'Python: {pver} tensorflow Ver: {tf.version.VERSION}' +
         '\nConvolutional neural network' + 
         f'\n{epochs} epochs, Duration: {duration:3.2f} seconds',# +
#         f'\n{gpus[0].name} Cuda 11.1.relgpu',
         wrap=True, ha='left', va='bottom',
         fontsize=9, bbox=dict(facecolor='aqua', alpha=0.5))
plt.text(10, .7, s='Increasing validation loss\n shows some overfitting',
         wrap=True, ha='left', va='top',
         fontsize=9, bbox=dict(facecolor='green', alpha=0.5))
plt.show()

#%% Plot confusion matrix
from sklearn.metrics import confusion_matrix
import itertools

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
  """
  This function prints and plots the confusion matrix.
  Normalization can be applied by setting `normalize=True`.
  """
  if normalize:
      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
      print("Normalized confusion matrix")
  else:
      print('Confusion matrix, without normalization')

  print(cm)

  plt.imshow(cm, interpolation='nearest', cmap=cmap)
  plt.title(title)
  #  plt.colorbar()
  tick_marks = np.arange(len(classes))
  plt.xticks(tick_marks, classes, rotation=90)
  plt.yticks(tick_marks, classes)

  fmt = '.2f' if normalize else 'd'
  thresh = cm.max() / 2.
  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
      plt.text(j, i, format(cm[i, j], fmt),
               horizontalalignment="center",
               color="white" if cm[i, j] > thresh else "black")

  plt.tight_layout()
  plt.ylabel('True label')
  plt.xlabel('Predicted label')
  plt.show()

p_test = model.predict(x_test).argmax(axis=1)
cm = confusion_matrix(y_test, p_test)

# plot_confusion_matrix(cm, list(range(10)))
# Label mapping
labels = '''0 T-shirt/top
1 Trouser
2 Pullover
3 Dress
4 Coat
5 Sandal
6 Shirt
7 Sneaker
8 Bag
9 Ankle boot'''.split("\n")

plot_confusion_matrix(cm, labels)

#%% Show some misclassified examples
misclassified_idx = np.where(p_test != y_test)[0]
i = np.random.choice(misclassified_idx)
plt.imshow(x_test[i].reshape(28,28), cmap='gray')
plt.title("True label: %s Predicted: %s" % (labels[y_test[i]], labels[p_test[i]]));

#%% Still to make this work...
# Iterate thru all the layers of the model
# for layer in model.layers:
#     if 'conv' in layer.name:
#         weights, bias= layer.get_weights()
#         print(layer.name, filters.shape)
        
#         #normalize filter values between  0 and 1 for visualization
#         f_min, f_max = weights.min(), weights.max()
#         filters = (weights - f_min) / (f_max - f_min)  
#         print(filters.shape[3])
#         filter_cnt=1
        
#         #plotting all the filters
#         for i in range(filters.shape[3]):
#             #get the filters
#             filt=filters[:,:,:, i]
#             #plotting each of the channel, color image RGB channels
#             for j in range(filters.shape[0]):
#                 ax= plt.subplot(filters.shape[3], filters.shape[0], filter_cnt  )
#                 ax.set_xticks([])
#                 ax.set_yticks([])
#                 plt.imshow(filt[:,:, j])
#                 filter_cnt+=1
#         plt.show()
        