# -*- coding: utf-8 -*-
"""TF2.0 Fashion MNIST.ipynb
13 June: Adding Tensorboard callbacks.
via TERMINAL command:  tensorboard --logdir d:\data\logs\mnist20210614_143149
Automatically generated by Colaboratory.

22 July 2021: Added 'Projector' call back...that's cool, but how to use it?'
22 July 2021: also added hParams.  Nice charts there. but, obvious.

Original file is located at
    https://colab.research.google.com/drive/1XeVQQdyGNptGWBLclF3yVijNir5-upkF
    
12 Jan: Fully functional in Environment: P37TF22cu7  (actually TF21)

Convolution 
    --> Image modification...either addition or multiplication (or both)
    --> ie feature transformation... 
        like taking just the lines from an image (edge detection filter)
        like bluring a picture (gaussian filter)

alternative description of convolution:
    "A sliding pattern finder (looking for particular pattern)"
    

UDEMY TENSORFLOW 2.0 LECTURE 35  MNIST IMAGE CLASSIFICATION FASHION 60,000 RECORDS
RUNNING ON GPU: TAKES 107.8 SECONDS 

  Notes from the lecture #35:
It's Conv23 because there are two spatial dimensions; color is not a spatial dimension'
A time-varing signal (sound) would use Conv1D... only dimension is sound
A video (height, Width, Time) would use Conv3d
Medical imaging data (like cancer images) would have height, width, depth (use Conv3D)
Conv3D would use Voxel(s) (volumn element vs picture element)

# output feature maps (32) 
Filter dimensions (3, 3) ... the spatial dimensions
Stride controls the speed of the filter
Activiation 
Padding arguement; default is 'valid'... which comes w/o an entry.

Convolution is pattern finding...so you might not usually do dropouts in convolution...
    because you don't want to remove pixels before looking for the pattern (stroke)
    if you remove pixels, is the 'stroke' still visible
Tensor24 env:
2021-06-13 14:14:46.038368: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cupti64_110.dll'; dlerror: cupti64_110.dll not found
2021-06-13 14:14:46.039384: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cupti.dll'; dlerror: cupti.dll not found
2021-06-13 14:14:46.040247: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.
2021-06-13 14:14:46.040300: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-06-13 14:14:46.040326: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1496] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.


# Commented out IPython magic to ensure Python compatibility.
# Install TensorFlow
# !pip install -q tensorflow-gpu==2.0.0-beta1

# try:
# #   %tensorflow_version 2.x  # Colab only.
# except Exception:
#   pass
"""
#%% Imports...
import numpy
import GPUtil
import numpy as np, matplotlib.pyplot as plt, os,pandas as pd
# 1 July 2021... next two statements...BEFORE any tensorflow did the trick.
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
import time, sys, tensorflow as tf
from datetime import datetime

import tensorboard ,sklearn.metrics, itertools, io
#https://neptune.ai/blog/tensorboard-tutorial
from tensorboard.plugins import projector
from tensorboard.plugins.hparams import api as hp
# from tensorboard.plugins import profiler_session
from tensorflow import keras
from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout
from tensorflow.keras.models import Model
import pydot, graphviz  #for graph of 
gpus = GPUtil.getGPUs()

#%% Get GPU status
from tensorflow.python.client import device_lib 
# print(device_lib.list_local_devices())  # this puts out a lot of lines (Gibberish?)
print('Conda Envronment:  ', os.environ['CONDA_DEFAULT_ENV'])
print(f'Gpu  Support:       {tf.test.is_built_with_gpu_support()}')
print(f'Cuda Support:       {tf.test.is_built_with_cuda()}')
print(f'Tensor Flow:        {tf.version.VERSION}')
pver = str(format(sys.version_info.major) +'.'+ format(sys.version_info.minor)+'.'+ format(sys.version_info.micro))
print('Python version:      {}.'.format(pver)) 
print('The numpy version:   {}.'.format(np.__version__))
print('The panda version:   {}.'.format(pd.__version__))
print('Tensorboard version  {}.'.format(tensorboard.__version__))
# additional imports

condaenv = os.environ['CONDA_DEFAULT_ENV']

modelstart = time.strftime('%c')
#%%  # Define the Keras TensorBoard callback.
label_dict = {  # NOT USED...but it adds clarity to see it.
            0:	'T-shirt/top',
            1:	'Trouser',
            2:	'Pullover',
            3:	'Dress',
            4:	'Coat',
            5:	'Sandal',
            6:	'Shirt',
            7:	'Sneaker',
            8:	'Bag',
            9:	'Ankle boot'
           }
logdir="d:/data/logs/hadelin/mnist/" + datetime.now().strftime("%Y%m%d_%H%M%S")
tensorboard_callback = keras.callbacks.\
    TensorBoard(log_dir=logdir,histogram_freq=1,  write_graph=True,
                write_images=True, update_freq='epoch',
                profile_batch=6, 
                embeddings_freq=1,
#                embeddings_metadata={layer_embed.name:'./logs/text_classify/word.tsv'})
#                embeddings_metadata='D:/Data/logs/hadelin/mnist/classes.tsv')
                embeddings_metadata='classes.tsv')
#              profile_batch='500,520')  #this seemed to fix the errors noted in the opening dialog above. :) 
file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')

HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([300, 200,512]))
HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1,0.5))
HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd', 'rmsprop']))

METRIC_ACCURACY = 'accuracy'
with tf.summary.create_file_writer(logdir + '/hparamTuning').as_default():
    hp.hparams_config(
        hparams=[HP_OPTIMIZER],
        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],)

#%% Load in the data
# Notice below, the dataset come INSIDE the tensorflow module...
# the 'load_data()' function returns two tuples.
# x_train is a numpy array (60000,  28, 28, 1); y_train(60000,)
fashion_mnist = tf.keras.datasets.fashion_mnist
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()
(x_img, y_img), (x_imgt, y_imgt) = fashion_mnist.load_data()

# Names of the integer classes, i.e., 0 -> T-short/top, 1 -> Trouser, etc.
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 
    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

#%%  # Creates a file writer for the log directory.
imagedir = logdir+'/imgs'
file_writer = tf.summary.create_file_writer(imagedir)

with file_writer.as_default():
  # Don't forget to reshape.
  images = np.reshape(x_train[0:25], (-1, 28, 28, 1))
  tf.summary.image("25 training data examples", images, max_outputs=25, step=0)

test_summary_writer = tf.summary.create_file_writer(logdir)
with test_summary_writer.as_default():
    tf.summary.scalar('loss', 0.345, step=1)
    tf.summary.scalar('loss', 0.234, step=2)
    tf.summary.scalar('loss', 0.123, step=3)  
#%% def plot_confusion_matrix
def plot_confusion_matrix(cm, class_names):
  """
  Returns a matplotlib figure containing the plotted confusion matrix.

  Args:
    cm (array, shape = [n, n]): a confusion matrix of integer classes
    class_names (array, shape = [n]): String names of the integer classes
  """
  figure = plt.figure(figsize=(8, 8))
  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
  plt.title("Confusion matrix")
  plt.colorbar()
  tick_marks = np.arange(len(class_names))
  plt.xticks(tick_marks, class_names, rotation=45)
  plt.yticks(tick_marks, class_names)

  # Compute the labels from the normalized confusion matrix.
  labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)

  # Use white text if squares are dark; otherwise black.
  threshold = cm.max() / 2.
  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    color = "white" if cm[i, j] > threshold else "black"
    plt.text(j, i, labels[i, j], horizontalalignment="center", color=color)

  plt.tight_layout()
  plt.ylabel('True label')
  plt.xlabel('Predicted label')
  plt.show()
  return figure
#%% def plot_to_image(figure):
def plot_to_image(figure):
  """Converts the matplotlib plot specified by 'figure' to a PNG image and
  returns it. The supplied figure is closed and inaccessible after this call."""
  # Save the plot to a PNG in memory.
  buf = io.BytesIO()
  plt.savefig(buf, format='png')
  # Closing the figure prevents it from being displayed directly inside
  # the notebook.
  plt.close(figure)
  buf.seek(0)
  # Convert PNG buffer to TF image
  image = tf.image.decode_png(buf.getvalue(), channels=4)
  # Add the batch dimension
  image = tf.expand_dims(image, 0)
  return image
#%%  def log_confusion_matrix(epoch, logs):
def log_confusion_matrix( epoch, logs):
  # Use the model to predict the values from the validation dataset.
  test_pred = np.argmax(test_pred_raw, axis=1)

  # Calculate the confusion matrix.
  cm = sklearn.metrics.confusion_matrix(y_test, test_pred)
  # Log the confusion matrix as an image summary.
  figure = plot_confusion_matrix(cm, class_names=class_names)
  cm_image = plot_to_image(figure)

  # Log the confusion matrix as an image summary.
  with file_writer_cm.as_default():
    tf.summary.image("Confusion Matrix", cm_image, step=epoch)

# Define the per-epoch callback.
#cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)

#%% Normalization / Data Prep
x_train, x_test = x_train / 255.0, x_test / 255.0
print("x_train.shape:", x_train.shape)  # (60000, 28, 28)
type(x_train)
# the data is only 2D!
# convolution expects height x width x color
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)
print(x_train.shape)

# number of classes...cast y_train to a 'set', which only has unique values
K = len(set(y_train))
print("number of classes:", K)  # ie 10 classes; we knew this already but good to show the general case
set(y_train)  # ie:  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}

# ####################################################
#%% BUILD THE MODEL and compile/fit using the functional API
def create_model(hparams):
    model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28)),
        tf.keras.layers.Dense(hparams[HP_NUM_UNITS],  activation='relu'),
        tf.keras.layers.Dropout(hparams[HP_DROPOUT]),
        tf.keras.layers.Dense(10, activation='softmax')])

    model.compile(optimizer=hparams[HP_OPTIMIZER],
                  loss='sparse_categorical_crossentropy',  
                  metrics=['accuracy'])

    model.fit(x_train, y_train, epochs=5,  callbacks=[tensorboard_callback]) #, cm_callback])
    loss, accuracy = model.evaluate(x_test, y_test)
    test_pred_raw  = model.predict(x_test) #ie... (test_images)

    return accuracy, test_pred_raw
#%%
def experiment(experiment_dir, hparams):

    with tf.summary.create_file_writer(experiment_dir).as_default():
        hp.hparams(hparams)
        accuracy, test_pred_raw = create_model(hparams)
        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)
 ##       return test_pred_raw
#%%
experiment_no = 0

for num_units in HP_NUM_UNITS.domain.values:
    for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):
        for optimizer in HP_OPTIMIZER.domain.values:
            hparams = {
                HP_NUM_UNITS: num_units,
                HP_DROPOUT: dropout_rate,
                HP_OPTIMIZER: optimizer,}

            experiment_name = f'Experiment {experiment_no}'
            print(f'Starting Experiment: {experiment_name}')
            print({h.name: hparams[h] for h in hparams})
            test_pred_raw = experiment(logdir+'/hparam_tuning/' + experiment_name, hparams)
            experiment_no += 1


print(f'Point tensorboard here: c:\\users\\steve>tensorboard --logdir {logdir}')

# tf.test.is_built_with_cuda()
# tf.test.is_built_with_xla()
# tf.test.is_gpu_available()
# tf.__all__
# tf.config.__package__
# tf.config.list_logical_devices()
# from tensorflow.python.platform import build_info as tf_build_info

# tf_build_info.build_info

