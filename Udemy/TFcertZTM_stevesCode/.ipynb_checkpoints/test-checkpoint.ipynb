{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jul 12 11:23:45 2021\n",
    "\n",
    "@author: steve\n",
    "\"\"\"\n",
    "import numpy as np, matplotlib.pyplot as plt, os, pandas as pd, seaborn as sns\n",
    "# 1 July 2021... next two statements...BEFORE any tensorflow did the trick.\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "import time , sys, tensorflow as tf, tensorboard, sklearn.metrics, itertools, io\n",
    "from datetime import datetime\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import pydot\n",
    "import graphviz  #for graph of \n",
    "import GPUtil\n",
    "gpus = GPUtil.getGPUs()\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"tensorflow\").addHandler(logging.NullHandler(logging.ERROR))\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# %% Get GPU status\n",
    "from tensorflow.python.client import device_lib \n",
    "# print(device_lib.list_local_devices())  # this puts out a lot of lines (Gibberish?)\n",
    "print('Conda Envronment:  ', os.environ['CONDA_DEFAULT_ENV'])\n",
    "print(f'Gpu  Support:       {tf.test.is_built_with_gpu_support()}')\n",
    "print(f'Cuda Support:       {tf.test.is_built_with_cuda()}')\n",
    "print(f'Tensor Flow:        {tf.version.VERSION}')\n",
    "pver = str(format(sys.version_info.major) +'.'+ format(sys.version_info.minor)+'.'+ format(sys.version_info.micro))\n",
    "print('Python version:      {}.'.format(pver)) \n",
    "print('The numpy version:   {}.'.format(np.__version__))\n",
    "print('The panda version:   {}.'.format(pd.__version__))\n",
    "print('Tensorboard version  {}.'.format(tensorboard.__version__))\n",
    "# additional imports\n",
    "\n",
    "condaenv = os.environ['CONDA_DEFAULT_ENV']\n",
    "\n",
    "modelstart = time.strftime('%c')\n",
    "!nvidia-smi\n",
    "\n",
    "# %% func: ChartMnistNetworkChanges dfLeft, dfRight, mdlsummary, dfLtime, dfRtime, rmdlsumry, changes\n",
    "def ChartMnistNetworkChanges(dfLeft, dfRight, mdlsummary, dfLtime, dfRtime, \n",
    "                             rmdlsumry, changes, supttl, ttl1, ttl2):\n",
    "    modelstart = time.strftime('%c')\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.suptitle(f'{supttl} {modelstart}')\n",
    "    plt.title (f'{ttl1} {dfLtime:.2f} sec ')\n",
    "    sns.lineplot(x='epochs', y='value', hue='variable', data = pd.melt(dfLeft,['epochs']))\n",
    "    plt.text(0., .5,# transform=trans1,\n",
    "              s=mdlsummary,\n",
    "              wrap=True, ha='left', va='bottom', fontname='Consolas',\n",
    "              fontsize=7, bbox=dict(facecolor='moccasin', alpha=0.5))\n",
    "    plt.legend(loc= 'lower left')\n",
    "    plt.ylim(.3,1)\n",
    "    plt.xlabel('epochs    \\GitHub\\DeepLearning')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.text(.0, .95,# transform=trans1,\n",
    "              s=changes,\n",
    "              wrap=True, ha='left', va='top', fontname='Consolas',\n",
    "              fontsize=9, bbox=dict(facecolor='aqua', alpha=0.5))\n",
    "    plt.text(0., .5,# transform=trans1,\n",
    "              s=rmdlsumry,\n",
    "              wrap=True, ha='left', va='bottom', fontname='Consolas',\n",
    "              fontsize=7, bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "    plt.title (f'{ttl2} {dfRtime:.2f} sec ')\n",
    "    sns.lineplot(x='epochs', y='value', hue='variable', data = pd.melt(dfRight,['epochs']))\n",
    "    plt.ylim(.3,1)\n",
    "    plt.xlabel('04transferLearning01FeatureExtraction.py    epochs')\n",
    "    plt.legend(loc= 'lower left')\n",
    "    plt.show();\n",
    "# %% func: view_random_image \n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "def view_random_image(target_dir, target_class):\n",
    "  # Setup target directory (we'll view images from here)\n",
    "  target_folder = target_dir+target_class\n",
    "\n",
    "  # Get a random image path\n",
    "  random_image = random.sample(os.listdir(target_folder), 1)\n",
    "\n",
    "  # Read in the image and plot it using matplotlib\n",
    "  img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
    "  plt.imshow(img)\n",
    "  plt.title(f'{target_class}   {img.shape}')\n",
    "  plt.axis(\"off\");\n",
    "\n",
    "  print(f\"Image shape: {img.shape}\") # show the shape of the image\n",
    "\n",
    "  return img\n",
    "# %%  Get the Data  commented out after completed\n",
    "import zipfile\n",
    "import wget\n",
    "'''\n",
    "url = 'https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip'\n",
    "output ='d:/data/udemy/dbourkeTFcert'\n",
    "dwnldFile = wget.download(url, out=output)  # this worked! :)\n",
    "destination = os.path.join(output, dwnldFile)  # this join gives two dif slashes :(\n",
    "\n",
    "zip_ref = zipfile.ZipFile(dwnldFile, \"r\")\n",
    "#zipfile.ZipFile.namelist('d:\\\\data\\\\udemy\\\\dbourkeTFcert\\\\10_Food_classes_10percent.zip')\n",
    "zipfile.ZipInfo.filename\n",
    "zip_ref.extractall(output)\n",
    "zip_ref.close()\n",
    "\n",
    "destination = 'd:\\\\data\\\\udemy\\\\dbourkeTFcert\\\\10_Food_classes_10_percent'\n",
    "for dirpath, dirnames, filenames in os.walk(destination):\n",
    "    print(f'There are {len(dirnames)} images and {len(filenames)} in {dirpath}')\n",
    "'''    \n",
    "# setup the train and test directories...\n",
    "train_dir = 'd:/data/udemy/dbourkeTFcert/10_Food_Classes_10_percent/train/'\n",
    "test_dir  = 'd:/data/udemy/dbourkeTFcert/10_Food_Classes_10_percent/test/'\n",
    "\n",
    "import pathlib\n",
    "data_dir = pathlib.Path(train_dir) # turn our training path into a Python path\n",
    "class_names = np.array(sorted([item.name for item in data_dir.glob('*')])) # created a list of class_names from the subdirectories\n",
    "print('class names are: ',class_names)\n",
    "\n",
    "view_random_image(train_dir, random.choice(class_names))\n",
    "\n",
    "# %% Create the data loaders\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "IMAGE_SHAPE= (224, 224)  # HYPER PARAMETER\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "test_datagen  = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "print(\"Training images:\")\n",
    "train_10pcbatch =\\\n",
    "    train_datagen.flow_from_directory(train_dir, \n",
    "                                      target_size=IMAGE_SHAPE,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      seed=42)\n",
    "print('Test images:')\n",
    "test_10pcbatch = \\\n",
    "    test_datagen.flow_from_directory(test_dir,\n",
    "                                     target_size=IMAGE_SHAPE,\n",
    "                                     batch_size=BATCH_SIZE,\n",
    "                                     seed=42)\n",
    "# %%  # Define the Keras TensorBoard callback.\n",
    "logdir=\"d:/data/logs/TFcertUdemy/04food10cls/\" \n",
    "def create_tb_callback(dirname, expname):\n",
    "    log_dir = logdir +dirname + '/' + expname+'_'  + datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir,\n",
    "              histogram_freq=1,                                     \n",
    "              profile_batch='500,520')  #this seemed to fix the errors noted in the opening dialog above. :) \n",
    "    hparams_callback = hp.KerasCallback(logdir, {'num_relu_units': 512,\n",
    "                                    'dropout': 0.2})\n",
    "    return tensorboard_callback\n",
    "\n",
    "# tf.keras.callbacks.\\\n",
    "#     TensorBoard(log_dir=logdir, histogram_freq=0, batch_size=32, \n",
    "#                 write_graph=True, write_grads=False, write_images=False, \n",
    "#                 embeddings_freq=0, embeddings_layer_names=None, \n",
    "#                 embeddings_metadata=None, embeddings_data=None, \n",
    "#                 update_freq='epoch')\n",
    "# Define the per-epoch callback. Confusion matrix\n",
    "# cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "# %% Create model with tensorflow hub\n",
    "# pulled this down from the tensorflowhub site...using the functionalized version from Daniel instead.\n",
    "# num_classes = 10\n",
    "# import tensorflow_hub as hub\n",
    "# from tensorflow.keras import layers\n",
    "# m = tf.keras.Sequential([\n",
    "#     hub.KerasLayer(\"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\",\n",
    "#                    trainable=False),  # Can be True, see below.\n",
    "#     tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "# ])\n",
    "# # m.build([None, expect_img_size, expect_img_size, 3])  # Batch input shape.    \n",
    "# m.build([None, 224, 224, 3])  # Batch input shape.    \n",
    "# %% Sources of models are:\n",
    "# Resnet 50 V2 feature vector\n",
    "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
    "\n",
    "# EfficientNet0 feature vector\n",
    "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n",
    "# %% func: pull in and define model\n",
    "def create_model(model_url, num_classes=10, mdl_name='Steve1'):\n",
    "    '''\n",
    "    Takes a Tensorflow HUB URL and creates a Keras Sequential model\n",
    "    Args:\n",
    "        model_url (str):  A tensorflow hub feature extractin URL.\n",
    "        num_classes (int): Number of output neuroons in the output layer,\n",
    "            should be equal to number of target classes, default of 10.\n",
    "    \n",
    "    Returns:\n",
    "        An uncompiled Keras Sequential  model with model_url as feature extractor\n",
    "        layer and Dense outut layer with num_classes output neurons.\n",
    "    '''\n",
    "    # Download the pretrained model and save it as a Keras layer\n",
    "    feature_extractor_layer \\\n",
    "        = hub.KerasLayer(model_url,\n",
    "                         trainable=False, # freeze already known patterns\n",
    "                         name='feature_extraction_layer',\n",
    "                         input_shape=IMAGE_SHAPE+(3,)) # add a dimension\n",
    "  \n",
    "    # Create our own model\n",
    "    model = tf.keras.Sequential([\n",
    "      feature_extractor_layer, # use the feature extraction layer as the base\n",
    "      layers.Dense(num_classes, activation='softmax', name='output_layer') # create our own output layer      \n",
    "    ], name = mdl_name)\n",
    "    return model                                           \n",
    "# %% Creating Resnet TF Hub model\n",
    "tbcb = create_tb_callback('tf_hub_src', 'resnet50v2')\n",
    "resnet_model = create_model(resnet_url, num_classes, 'resnet50v2')\n",
    "resnet_model.summary()\n",
    "resnet_model.compile(loss='categorical_crossentropy',\n",
    "                     optimizer=tf.keras.optimizers.Adam(),\n",
    "                     metrics='accuracy')\n",
    "starttime = time.perf_counter()\n",
    "\n",
    "resnethist = resnet_model.fit(train_10pcbatch, batch_size=BATCH_SIZE, epochs=5,\n",
    "                 validation_data=test_10pcbatch, \n",
    "                 validation_steps=len(test_10pcbatch)\n",
    "                 , callbacks=[tbcb])\n",
    "endtime = time.perf_counter()\n",
    "print(f'Point tensorboard here: c:\\\\users\\\\steve>tensorboard --logdir {logdir}')\n",
    "\n",
    "# %% Prepare df's for the chart\n",
    "# record time data\n",
    "resnetdur = round(endtime - starttime,2)\n",
    "resnetdf = pd.DataFrame(resnethist.history).reset_index()\n",
    "#df.drop('lr', axis=1, inplace=True)\n",
    "resnetdf.rename(columns = {'index':'epochs'}, inplace=True)\n",
    "resnetdf\n",
    "\n",
    "resnet = resnet_model.summary()\n",
    "stringlist2 = []\n",
    "resnet_model.summary(print_fn=lambda x: stringlist2.append(x))\n",
    "resnetmdlsum = \"\\n\".join(stringlist2)\n",
    "resnetmdlsum = resnetmdlsum.replace('_________________________________________________________________\\n', '')\n",
    "\n",
    "# %% sHOW the chart...\n",
    "supttl = 'Udemy TF Certify ZtoM 10 Food Classification Models Lecture 143'\n",
    "lftTtl = '\"By hand\" Convolutional Model'\n",
    "rhtTtl = 'Transfer Learning Resnet50v2'\n",
    "augmnt = '''From \"TensorFlowHub\", the borrowed model is over twice\n",
    " faster, and over twice as accurate!!!'''\n",
    "ChartMnistNetworkChanges(histFood3df, resnetdf, foodmdl3sum, foodmdl3dur,\n",
    "                         resnetdur,resnetmdlsum,  augmnt, supttl, lftTtl,rhtTtl)\n",
    "# pd.DataFrame(resnetdf.drop('epochs', axis=1)).plot(figsize=(10,7))\n",
    "\n",
    "# %% Now, bring in Efficient net...compare to resnet...\n",
    "tbcb = create_tb_callback('tf_hub_src', 'effnetB0')\n",
    "effnet_model = create_model(efficientnet_url, num_classes, 'EfficientNetB0')\n",
    "effnet_model.summary()\n",
    "effnet_model.compile(loss='categorical_crossentropy',\n",
    "                     optimizer=tf.keras.optimizers.Adam(),\n",
    "                     metrics='accuracy')\n",
    "starttime = time.perf_counter()\n",
    "\n",
    "effnethist = effnet_model.fit(train_10pcbatch, batch_size=BATCH_SIZE, epochs=5,\n",
    "                 validation_data=test_10pcbatch, \n",
    "                 validation_steps=len(test_10pcbatch)\n",
    "                 , callbacks=[tbcb])\n",
    "endtime = time.perf_counter()\n",
    "print(f'Point tensorboard here: c:\\\\users\\\\steve>tensorboard --logdir {logdir}')\n",
    "# %% Prepare df's for the chart\n",
    "# record time data\n",
    "effnetdur = round(endtime - starttime,2)\n",
    "effnetdf = pd.DataFrame(effnethist.history).reset_index()\n",
    "#df.drop('lr', axis=1, inplace=True)\n",
    "effnetdf.rename(columns = {'index':'epochs'}, inplace=True)\n",
    "effnetdf\n",
    "\n",
    "effnet = effnet_model.summary()\n",
    "stringlist2 = []\n",
    "effnet_model.summary(print_fn=lambda x: stringlist2.append(x))\n",
    "effnetmdlsum = \"\\n\".join(stringlist2)\n",
    "effnetmdlsum = effnetmdlsum.replace('_________________________________________________________________\\n', '')\n",
    "# %% sHOW the chart...\n",
    "supttl = 'Udemy TF Certify ZtoM 10 Food Classification Models Lecture 145'\n",
    "lftTtl = 'Transfer \"Resnet50v2\" CNN'\n",
    "rhtTtl = 'Transfer \"EfficientNet\" CNN'\n",
    "augmnt = '''From \"TensorFlowHub\", the efficientNet model is even faster\n",
    " , and more accurate still!!!  AND, only using 10% of the \n",
    " training images...which is why it is so fast.\n",
    " \n",
    " All features (weights/bias) in the feature extractor are \n",
    " frozen!\n",
    " \n",
    " This is FEATURE EXTRACTION TRANSFER LEARNING.'''\n",
    "ChartMnistNetworkChanges(resnetdf,effnetdf, resnetmdlsum, resnetdur,\n",
    "                         effnetdur,effnetmdlsum,  augmnt, supttl, lftTtl,rhtTtl)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
